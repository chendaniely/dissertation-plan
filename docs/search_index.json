[
["index.html", "Dissertation Outline Planning", " Dissertation Outline Daniel Chen 2020-02-26 Planning The outline of my dissertation on data science and data literacy education for medical professionals. "],
["overall-groups-an-questions.html", "Chapter 1 Overall Groups an Questions 1.1 Sample groups 1.2 Experiments", " Chapter 1 Overall Groups an Questions 1.1 Sample groups Workshop attendees where the main population of learners are comming from a medical background. Workshop attendees (this will be a series of convenience samples) What are potential issues and biases with this sample? Population will be self-selecting and more likely to be self-motivated Workshop attendees where the main population of learners are students (undergraduate/graduate) Also self-selecting Lessons taught at as a university course Small modules taught as a part of a university course 1.2 Experiments Hypothesis: In-person workshops will help medical professionals curate better for research Hypothesis: In-person workshops will help medical professionals work with data outside of a spreadsheet program Hypothesis: Workshops with an eye towards tidy data principles will better transition students out of a spreadsheet program into programming Hypothesis: Learning how to program data analysis will allow learners to feel like they can do more with their data "],
["rough-scope.html", "Chapter 2 Rough scope 2.1 What will learners do along the way?", " Chapter 2 Rough scope A rough scope for the lesson (questions taken from “Teaching Tech Together”) What problems will people learn how to solve? Collect data so it can be easily transformed for analysis Generate reproducible analysis reports (figures, calculations, summary statistics, tables), even when the data changes Load data from Excel, SAS, and CSV files. What concepts and techniques will people learn? Components of tidy data Loading datasets into R/Python Visualizing data, calculate summary statistics, generate tables into reports What technologies, packages, or functions will people use? What terms or jargon will you define? What analogies will you use to explain concepts? What mistakes or misconceptions do you expect? What datasets will you use? Ebola: https://github.com/cmrivers/ebola Zika: https://github.com/cdcepi/zika Coronavirus Census TCGA: https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga ICD codes: https://healthdata.gov/dataset/hospital-inpatient-diagnosis-procedure-and-external-cause-codes 2.1 What will learners do along the way? Full descriptions of a couple of exercises that learners will do at the end of the lesson. Fully explained exercises that use the skills people are to learn Exercise outlines + complete solutions "],
["lesson-outline.html", "Chapter 3 Lesson Outline", " Chapter 3 Lesson Outline Outline the lesson first, then write overview Outline: order of exercises, 1 hour blocks, formative assessment Overview: description, learning objectives, summary of prerequisites "],
["feedback-and-assessment.html", "Chapter 4 Feedback and Assessment 4.1 Teaching evaluations 4.2 Student self-assessments 4.3 Pre/Post assessments 4.4 Long-term assessments", " Chapter 4 Feedback and Assessment 4.1 Teaching evaluations (Taken from “Teaching Tech Together” and “How Learning Works”) Rubric to assess teaching Opening: Exists, Length, Intro self, intro topics covered, describes prerequisites Content: clear goal/narrative arc; inclusive language; authentic tasts/examples; Teaches best practices/idiomatic code; balances jargon and over-simplification Delivery: clear intelligible voice; rhythm and pacing; self-asssured Slides: I’m probably not going to use, may have written tutorial matierls for reference and future self learning Exist; slides and speech complement one another (dual coding); readable fonts and colors; frequent change on screen; good use of graphics Live coding: used; code and speech complement one another (dual coding); readable fonts and colors/right amount of code on the screen; proficient use of tools; highlights key features of code; dissects errors Closing: exists; good lenth; summarizes key points; outlines next steps Overall: points clearly connected/logical flow; makethe topic interesting; knowledgeable 4.2 Student self-assessments Means to gather feedback on students’ prior knowledge and skills goal: get range of abilities and experiences for the class Used to calibrate materials and/or provide supplemental materials Help students focus on most important knowledge and skills addressed by the course advantage: easy to construcy, score, adminster anonymously, low-anxiety for students weakness: students may not accurately assess their abilities (usually people over estimate) Assessments around why they are attending the class/workshop What do they plan to learn What are the types of questions they are trying to answer? I want to collect data for a chart review and want to know what I should collect and how to format my data I have data that I want to analyze, but do not know where to start 4.2.1 Example questions How familiar are you with Excel? I have never used it, or I have tried it but coun’t really do anything with it. I have used it as an electronic todo list and planner putting schedules and task deadlines in a single place I’ve used it to store datasets and able to calculate basic aggregate values, such as mean I’ve used data aggregation, pivot tables, formulas, and plotting feature to understand how my data breaks down. I’ve coded up VBA macros and made VOOKUP calls integrating multiple sheets for a simulation task How familar are you with a “t-test”? I’ve never heard of it. I have heard of it but don’t remember what it is. I have some idea of what it is, but am not too clear I know what it is and could explain what it’s for. I know what it is and when to use it and could use it to analyze data. How do you manage your data and analysis? I don’t do data and/or analysis work My data and analysis are all in excel files, possibly with multiple sheets. I work on carefully time-stamped excel files for my version control and analysis I use some programming language to load in my data sets for analysis, but sometimes modify my orginal data files when cleaning the data I hold my original data sacred, and only work on it from another program and save out intermediate and final data prodects as separate files I have a very specific project strcture where data and analysis are kept in separate areas and have a version control system (e.g., Git, SVN) I have version controled project templates along with build scripts (e.g., Makefile) to reproduce various aspects of the analysis How familiar are you with interactie programming languages like Python or R I do not know what those are I have heard of them but have never used them before I have installed it, but have only done simple examples with them I have written a small program with them before I use it to automate certain repetitive tasks I have small side projects that I program in it I program in them for work Need question about tidy datasets how do you know a dataset is clean (enough)? 4.3 Pre/Post assessments This is different from formative/summative assessment Gauge prior programming knowledge of participants for ds4med workshop. 4.3.1 Example questions Which of these best describes your experience with programming in general? I have none. I have written a few lines now and again. I have written programs for my own use that are a couple of pages long. I have written and maintained larger pieces of software. What of these best describes your experience with programming in Python/R? I have none I have written a few lines now and again. I have written programs for my own use that are a couple of pages long. I have written and maintained larger pieces of software. Which of these best describes how easily you could write a program in any languate to find the largest number in a list? I wouldn’t know where to start I could struggle through by trial and error with a lot of web searches I could do it quickly with little or no use of external help Which of these best describes how easily you could write a Python/R program to find and capitalize all of the titles in a web page? I wouldn’t know where to start I could struggle through by trial and error with a lot of web searches I could do it quickly with little or no use of external help What do you want to know or be able to do after this class that you don’t know or can’t do right now? 4.4 Long-term assessments https://datacarpentry.org/blog/2017/03/long-term-assessment-strategy https://carpentries.github.io/assessment/learner-assessment/archives/2017/code/longtermreport_October2017.html Establishing value is not just important for funding, it is also import for the community (volunteers percieve they are doing important work) Data Carpentry post-workshop survey results: respondents are “enthusiastically” or “very” involved in the workshops what impact workshops are having on learners’ confidence in the skills they are taught goal is to have students describe concrete changes they had implemented to their research practices as a result of completing a Carpentries workshop. Do they have greater confidence in the tools they had been taught whether they had progressed in their careers as a result. multipl chose questions around progarmming in R and Python helped make the evidence of training efficacy more concrete, comparable and measurable taking it out of the realm of “opinion” or “feeling” for more robust/reliable markers results are self-reported respondents my exaggerate their achievements results affected by individual’s state of mind Response rate higher among those who feel more positive Compared long-term survey results with post-workshop results https://github.com/carpentries/assessment 4.4.1 Questions to ask 4.4.1.1 Workshop impact Reproduducible: I have made my analyses more reproducible as a result of completing the workshop Recognition: I have received professional recognition for my work as a result of using the tools I learned at teh workshop Productivity: My research productivity has improved as a result of completing the workshop Motivation: I have been motivated to seek more knowledge about the tools I learned at the workshop Confidence: I have gained conficdence in working with data as a result of completing the workshop Coding: I have improved my coding practices as a result of completing the workshop Career: I have used skills I learned at the workshop to advance my career From the Carpentries Long-term survery results, people post workshop seem to follow more FAIR principles 4.4.1.2 Behaviours respondents adopted Using programming languages like R or Python, or the command line to automate repetitive tasks Improving dtaa management and project organization Using version control to manage code Resusing code Sharing code or data publicaly on places like GitHub or FigShare Using databases, scripts, and queries to manage large data sets Using version control to collaborate online (in public or private repositores) Transforming step-by-step workflows into scripts or functions Developing a data management and analysis plan 4.4.1.3 Change in confidence Confidence helps build self-guided learning 4.4.1.4 Useage of tools for research and/or work They are improving my overall efficiency They are imporoving my ability to analyze data They are improving my ability to manage data I am not using the tools I learned The tools I learned have not helped me with my work 4.4.1.5 Contributions to academic writing Tools learned to contribute to academic writing (e.g., grant proposal, journal article). i.e., research dissemination 4.4.1.6 Continuout learning What liearning activities they have participated in since attening workshop Used non-carpentry self-guided material used self-guided Carpentry lesson material Participated in an in-person short course Participated in an online short course Participated in a Meetup Participated in a semester long course The Journal of Open Source Education (JOSE): https://jose.theoj.org/about "],
["education.html", "Chapter 5 Education 5.1 Bloom’s taxonomy 5.2 Learning Objectives 5.3 Learner Personas 5.4 Statistics methods", " Chapter 5 Education 5.1 Bloom’s taxonomy (Mary forehand, University of Georgia) Old New Evaluate Creating Synthesis Evaluating Analysis Analyzing Application Applying Comprehension Understanding Knowledge Remembering Cognitive Process Knowledge Remember Understand Apply Analyze Evaluate Create Factual List Summarize Classify Order Rank Combine Conceptual Describe Interpret Experiment Explain Assess Plan Procedural Tabulate Predict Calculate Differentiate Conclude Compose Meta-cognitive Appropriate Use Execute Construct Achieve Action Actualize Remember: arrange, define, describe, duplicate, identify, label, list, locate, name, recall, recite, recognize, reproduce, select, state Understand: associate, classify, compare, contrast, describe, differentiate, discuss, exemplify, explain, infer, interpret, paraphrase, restate, summarize, translate Apply: calculate, construct, demonstrate, develop, employ, estimate, examine, execute, formulate, implement, modify, sketch, solve, use Analyze: break down, combine, compare, contrast, debate, diagram, examine, experiment, extrapolate, formulate, illustrate, organize, predict, question Evaluate: appraise, argue, assess, check, conclude, critique, detect, judge, justify, monitor, rank, rate, recommend, select, test, weigh Create: assemble, build, compose, construct, design, formulate, generate, integrate, produce, propose, rearrange, set up, transform 5.2 Learning Objectives Student centered Break down the task and focus on specific cognitive processes Use action verbs to focus on concrete actions and behaviors Measurable. e.g., state, solve, identify By the end of the course students should be able to: “Design an experimental study, carry out an appropriate statistical analysis of the data, and properly interpret and communicate the analysis)” (decision sciences) name the features of tidy (clean) dataset describe when spreadsheets are useful assess when a task should not be done in spreadsheet software construct a plot and table for exploratory data analysis 5.3 Learner Personas 5.3.1 Personas Each persona should have The person’s general background What they already know What they think they want to do Any special needs they have Main groups of students Medical / osteopathic doctors Nurses MD PhD programs Analysis hired to work in the medical field Persona In Brief Domain Stats Programming Data Example Academic Professor who needs to train students expert competent competent competent Anne Excel Researcher who primarily uses excel for analysis work competent novice novice novice Generalist Data scientist working in the hospital expert expert expert competent Daniel Librarian Data specialist to help with data needs competent competent novice expert Newbie A medical student looking to get into research novice novice novice novice Tech The system administrator for the hospital data expert novice expert expert Researcher RN PhD or MD PhD student expert novice novice competent Jackie Leader Department head in charge of planning education expert novice novice novice Need: researcher who is domain(expert), stats(novice), programming(expert), data(competent) 5.4 Statistics methods Statistics methods used in research: logistic regression survival methods "],
["core-data-knowledge.html", "Chapter 6 Core data knowledge 6.1 Excel 6.2 Tidy data 6.3 Workflow managment 6.4 Learning how to program", " Chapter 6 Core data knowledge 6.1 Excel Excel can be thought of as a GUI for data. You see the individual Pro: Spreadsheets are everywhere Has support for libreoffice https://help.libreoffice.org/6.2/en-US/text/sbasic/shared/vbasupport.html VBA is relatively “easy” to learn Con: Data is getting bigger, and it does not scale Reproducible workflows require you to program free online books and resources (need to check for this) Inflexible, e.g., querying apis, social network analysis, gis More flexible programming languages grow with the user. Load data Do analysis Connect to a database Fit statistical models Create and deploy dashboards Create and deploy web artifacts (websites, blogs, books) Hardware + software projects 6.2 Tidy data Need to formalize my own anecdotes and reflections from teaching into something more academic. Over the years while teaching half day workshops at conferences, I’ve completely shifted tidy data and functions to the very beginning of the materials needed in an intro class. This seems to be the most efficient use of workshop time when students have access to an instructor for questions, while covering the more complicated topics in data processing and programming. Many of the other skills in data cleaning, can be more easily picked up on their own by reading the documentation, or looking at examples. Tidy data principles (https://www.jstatsoft.org/article/view/v059i10) is fundamental to understanding data processing. Since a huge amount of effort is spent cleaning and processing data, understanding what makes data tidy, provides the roadmap on how to clean and process data for data exploration and analysis. This provides a framework for understanding how to collect data, and how to transform data collected in the field. If everyone on the team has an understanding on these principles, then transforming the shape of the data needed for collection, presentation, and analysis, can be easily done between all members in an analysis project. This helps the analyst understand why the data they got was in the shape its in, and helps the field worker understand why so much more time is needed to process data they collected, and smarter decisions can be made throughout the entire process. not only does tidy data principles provide a guide to how to clean data, it’s the gateway to learn all the other required data science skills (e.g., plotting, applying functions, dealing with missing data, etc) This also separates the technical knowledge of working with software with the theoretical knowledge of cleaning data for analysis. Once the theory is understood, it can reduce the learning load needed to pick up the technical programming knowledge. Everything all stems from understanding tidy data. 6.3 Workflow managment 6.3.1 Naming things Jenny bryan probably has the clearest slide deck explaining how to name things: https://speakerdeck.com/jennybc/how-to-name-files machine readable regular expression and globbing friendly avoid spaces, punctuation, accented characters, case sensitivity easy to compute on deliberate use of delimiters easy to search for files later easy to narrow file lists based on names easy to extract info from file names (e.g., by splitting) human readable name contains info on content connects to concept of slug from semantic URLs plays well with default ordering put something numeric first chronological order logical order ISO 8601 standard for dates left pad other numbers with zeros 6.3.2 Project templates/folder structures https://daniel.rbind.io/2017/05/30/project-templates/ https://daniel.rbind.io/2018/01/23/analysis-based-project-templates/ project | |- data # raw and primary data, are not changed once created | | | |- project_data # subfolder that links to an encrypted data storage container | | | | | |- original # raw data, will not be altered | | |- working # intermediate datasets from src code | + +- final # datasets used in analysis | |- src / # any programmatic code | |- user1 # user1 assigned to the project | +- user2 # user2 assigned to the project | |- output # all output and results from workflows and analyses | |- figures/ # graphs, likely designated for manuscript figures | |- pictures/ # diagrams, images, and other non-graph graphics | +- analysis/ # generated reports for (e.g. rmarkdown output) | |- README.md # the top level description of content | |- Makefile # Makefile, if applicable |- .gitignore # git ignore file +- project.Rproj # RStudio project 6.3.3 Software R: https://github.com/r-lib/rprojroot, https://github.com/r-lib/here Python: https://github.com/chendaniely/pyprojroot 6.4 Learning how to program For data provenance. Doing all the processing in a GUI (Excel is a GUI for data processing), is not easily replicicatble. Excel is a GUI for data. and programming in excel is really programming the GUI, rather than working directly on the data. It adds an additional layer of complexity when you need to manipulate data, since you need to wrangle the GUI itself. There’s already replication crisis in science. One could argue that the findings in medical research are more likely going to affect actual people. Flexibilty for life: Languages like R any Python allow the user to learn what they need at the time while still providing the mechanisms to grow as their needs and skills grow. Many other tools have a hard point 6.4.1 Data literacy training for biomedical and health professionals "],
["rationale.html", "Chapter 7 Rationale 7.1 Medical education 7.2 Workshops and higher education 7.3 Data science education", " Chapter 7 Rationale 7.1 Medical education The curriculum is full. If we want to integrate new material into the these programs, we need to think long and hard about what needs to come out. From personal experience: throwing in programming labs is not effective, since it becomes a process of doing the bare minimum of getting the lab finished. 7.1.1 Existng adjacent classes Example 4 year medical and nursing program coursework. 7.1.1.1 Nursing BSN South Carolina (https://www.sc.edu/study/colleges_schools/nursing/academic_programs/bs_nursing/fall2014programinfo/sample_bsn_curriculum.php) Elementary statistics for the biological and life sciences Evidence-based Nursing Practice U Pitt Nursing informatics Introduction to basic statistics for evidence-based practice 7.2 Workshops and higher education Can these skills be taught to students in masters or PhD programs? Or smaller workshops for working professionals. Nurses: NP programs, DrNP, and PhD programs Medical Doctors: 7.3 Data science education 7.3.1 Data science education in medicine (See intital prospectus) "],
["learning.html", "Chapter 8 Learning 8.1 Motivation 8.2 Develop mastery 8.3 Practice and Feedback 8.4 Self-directed learners", " Chapter 8 Learning 8.1 Motivation 8.2 Develop mastery 8.3 Practice and Feedback busy professionals need to have focused and targeted practice to maximize the efficient use of time. minimize the amount of time misspent [hlw]. “[s]tudents often need significantly more guidance and structure than we would expect in order to direct their efforts productively” [hlw] 8.3.1 Learnr + gradethis R packages software that allows for learning, practice, and feedback. These could be used to reduce the load on the instructor by providing a mechanism in the classroom to triage student help. Or can be provided as supplemental practice materials. 8.4 Self-directed learners "],
["community-of-practice.html", "Chapter 9 Community of practice", " Chapter 9 Community of practice People cycle in and out. How does this dissertation project pave the way of building a community, such that it scales to multiple instructors, and grows with learner’s needs. The Carpentries is only one way to keep a core set of materials up-to-date, but what about other semester long classes? At the university (Virginia Tech), there are already existing programs such as SAGE (statistics) and DataBridge (Library) that serve as a resource for researchers to get help with data work, How do we take these data science meetup communities, and apply them to a undergraduate university setting? "],
["references.html", "References", " References "]
]
